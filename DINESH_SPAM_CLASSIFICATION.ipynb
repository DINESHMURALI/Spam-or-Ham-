{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f69bb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#labelling text for spam and ham as 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5fccee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "spam_emails_path = \"C:/Users/Admin/Desktop/spam\"\n",
    "ham_emails_path =\"C:/Users/Admin/Desktop/ham\"\n",
    "\n",
    "labeled_file_directories = [(spam_emails_path, 0), (ham_emails_path,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a8cd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding text and labels to the list\n",
    "# replace \\n "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38e1cd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_corpus = []\n",
    "labels = []\n",
    "\n",
    "for class_files, label in labeled_file_directories:\n",
    "    files = os.listdir(class_files)\n",
    "    for file in files:\n",
    "        file_path = os.path.join(class_files, file)\n",
    "        try:\n",
    "            with open(file_path, \"r\") as currentFile:\n",
    "                email_content = currentFile.read().replace(\"\\n\", \"\")\n",
    "                email_content = str(email_content)\n",
    "                email_corpus.append(email_content)\n",
    "                labels.append(label)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f068dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and test split from the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "119c78ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(email_corpus, labels, test_size=0.2, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbec1f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating single pipline for vectorizer and train model\n",
    "#hashing vectorizer I have used for processing speed due to large set of text\n",
    "#Tfidf I used after hashing so the dimensionality will be minimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a83250d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', HashingVectorizer(ngram_range=(1, 3))),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('dt', DecisionTreeClassifier(class_weight='balanced'))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import HashingVectorizer, TfidfTransformer\n",
    "from sklearn import tree\n",
    "\n",
    "nlp_followed_by_dt = Pipeline(\n",
    "    [\n",
    "    (\"vect\", HashingVectorizer(input=\"content\", ngram_range=(1,3))),\n",
    "    (\"tfidf\", TfidfTransformer(use_idf=True,)),\n",
    "    (\"dt\", tree.DecisionTreeClassifier(class_weight=\"balanced\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "nlp_followed_by_dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0382b1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#score for training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eade98fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(nlp_followed_by_dt.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0d50b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = nlp_followed_by_dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e3b2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix for the actual and the predicted output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b28fb1cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[100   0]\n",
      " [  0 510]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       100\n",
      "           1       1.00      1.00      1.00       510\n",
      "\n",
      "    accuracy                           1.00       610\n",
      "   macro avg       1.00      1.00      1.00       610\n",
      "weighted avg       1.00      1.00      1.00       610\n",
      "\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "result = confusion_matrix(y_test, ypred)\n",
    "print('Confusion Matrix:')\n",
    "print(result)\n",
    "result1 = classification_report(y_test, ypred)\n",
    "print('Classification Report:')\n",
    "print (result1)\n",
    "result2 = accuracy_score(y_test,ypred)\n",
    "print('Accuracy:',result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c59e00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
